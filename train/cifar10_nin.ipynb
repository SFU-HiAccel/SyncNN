{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10_nin.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1XRGlRat07X"
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras import optimizers\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, AveragePooling2D\n",
        "from keras.callbacks import LearningRateScheduler, TensorBoard\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.initializers import he_normal\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras import backend\n",
        "\n",
        "weight_decay= 0.0001\n",
        "batch_size    = 128\n",
        "epochs        = 200\n",
        "iterations    = 391\n",
        "num_classes   = 10\n",
        "dropout = 0.4\n",
        "\n",
        "\n",
        "def build_model():\n",
        "  model= Sequential()\n",
        "\n",
        "  model.add(Conv2D(192,(5,5),padding='same',use_bias=False,kernel_initializer=he_normal(),activation='relu',input_shape=(32,32,3),kernel_regularizer=keras.regularizers.l2(weight_decay)))\n",
        "  model.add(Conv2D(192,(1,1),padding='same',use_bias=False,kernel_initializer=he_normal(),activation='relu',kernel_regularizer=keras.regularizers.l2(weight_decay)))\n",
        "  model.add(Conv2D(192,(1,1),padding='same',use_bias=False,kernel_initializer=he_normal(),activation='relu',kernel_regularizer=keras.regularizers.l2(weight_decay)))\n",
        "  model.add(AveragePooling2D(pool_size=(3, 3),strides=(2,2),padding = 'same'))\n",
        "  \n",
        "  \n",
        "  model.add(Conv2D(192,(5,5),padding='same',use_bias=False,kernel_initializer=he_normal(),activation='relu',kernel_regularizer=keras.regularizers.l2(weight_decay)))\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Conv2D(192,(1,1),padding='same',use_bias=False,kernel_initializer=he_normal(),activation='relu',kernel_regularizer=keras.regularizers.l2(weight_decay)))\n",
        "  model.add(Conv2D(192,(1,1),padding='same',use_bias=False,kernel_initializer=he_normal(),activation='relu',kernel_regularizer=keras.regularizers.l2(weight_decay)))\n",
        "  model.add(AveragePooling2D(pool_size=(3, 3),strides=(2,2),padding = 'same'))\n",
        "  model.add(Dropout(0.4))\n",
        "  \n",
        "  model.add(Conv2D(192,(5,5),padding='same',use_bias=False,kernel_initializer=he_normal(),activation='relu',kernel_regularizer=keras.regularizers.l2(weight_decay)))\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Conv2D(192,(1,1),padding='same',use_bias=False,kernel_initializer=he_normal(),activation='relu',kernel_regularizer=keras.regularizers.l2(weight_decay)))\n",
        "  model.add(Conv2D(10,(1,1),padding='same',use_bias=False,kernel_initializer=he_normal(),activation='relu',kernel_regularizer=keras.regularizers.l2(weight_decay)))\n",
        "  model.add(GlobalAveragePooling2D())\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  opt = optimizers.SGD(momentum=0.9)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "#load data\n",
        "(x_train,y_train),(x_test,y_test)=cifar10.load_data()\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "y_train = np_utils.to_categorical(y_train, 10)\n",
        "y_test = np_utils.to_categorical(y_test, 10)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "m=np.max(x_train)\n",
        "x_train=(x_train)/m\n",
        "x_test=(x_test)/m\n",
        "\n",
        "def scheduler(epoch):\n",
        "    if epoch <= 80:\n",
        "        return 0.05\n",
        "    if epoch <= 121:\n",
        "        return 0.005\n",
        "    if epoch <= 200:    \n",
        "        return 0.0005\n",
        "\n",
        "change_lr = LearningRateScheduler(scheduler)\n",
        "cbks = [change_lr]\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(horizontal_flip=True,width_shift_range=0.125,height_shift_range=0.125,fill_mode='constant',cval=0.)\n",
        "datagen.fit(x_train)\n",
        "\n",
        "\n",
        "model=build_model()\n",
        "print(model.summary())\n",
        "history=model.fit_generator(datagen.flow(x_train, y_train,batch_size=batch_size),steps_per_epoch=iterations,epochs=epochs, validation_data=(x_test, y_test),callbacks=cbks, shuffle=True)\n",
        "\n",
        "\n",
        "model.save('cifar10_nin.h5')\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['train', 'val'])\n",
        "plt.show()\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.legend([ 'val'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}